—Å–æ–≥–ª–∞—Å–µ–Ω ‚Äî –≤ –ø—Ä–µ–¥—ã–¥—É—â–µ–π –≤–µ—Ä—Å–∏–∏ —á–∞—Å—Ç—å CLI-—Ñ–ª–∞–≥–æ–≤ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ ¬´—Ç–µ—Ä—è–ª–∞—Å—å¬ª –∏ –ø–æ–¥—Å—Ç–∞–≤–ª—è–ª–∏—Å—å –¥–µ—Ñ–æ–ª—Ç—ã. –ù–∏–∂–µ —è –¥–∞—é **–≥–æ—Ç–æ–≤—ã–µ —Ñ–∞–π–ª—ã**, –≥–¥–µ —Ñ–ª–∞–≥–∏ –ø—Ä–∞–≤–∏–ª—å–Ω–æ –ø—Ä–æ–∫–∏–Ω—É—Ç—ã –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ —Ä–µ–∂–∏–º—ã: —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ (stream/parallel) –∏ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ (merge).

–î–æ–±–∞–≤–ª–µ–Ω–æ/–∏—Å–ø—Ä–∞–≤–ª–µ–Ω–æ:

* `--exclude` –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø—Ä–∏ –æ–±—Ö–æ–¥–µ (–∏ –≤ stream, –∏ –≤ parallel).
* `--output`, `--pretty` —É—á–∏—Ç—ã–≤–∞—é—Ç—Å—è –ø—Ä–∏ —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –∑–∞–ø–∏—Å–∏.
* `--workers` —É–ø—Ä–∞–≤–ª—è–µ—Ç –ø—É–ª–æ–º –≤–æ—Ä–∫–µ—Ä–æ–≤.
* `--no-md5` –æ—Ç–∫–ª—é—á–∞–µ—Ç –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ MD5.
* `--io-limit` –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ—Ç –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ I/O (—É—á–∏—Ç—ã–≤–∞–µ—Ç—Å—è –≤ ReadDir/MD5).
* `--dedupe` –ø—Ä–∏–º–µ–Ω—è–µ—Ç—Å—è –≤ merge.
* `--merge-flat` –∏ `--merge-children` –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –≤–ª–∏—è—é—Ç –Ω–∞ —Ç–∏–ø —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –∏ —Å—Ç—Ä–∞—Ç–µ–≥–∏—é –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è.
* `--resume` –ø–æ–∫–∞ –æ—Ç–º–µ—á–µ–Ω –∫–∞–∫ TODO (—Å–æ–æ–±—â–µ–Ω–∏–µ –≤—ã–≤–æ–¥–∏—Ç—Å—è —è–≤–Ω–æ).

> –Ø –¥–æ–±–∞–≤–∏–ª –º–∞–ª–µ–Ω—å–∫–∏–π —Å–ª–æ–π –∫–æ–Ω—Ñ–∏–≥–æ–≤ `internal/app/config.go`, —á—Ç–æ–±—ã –ø—Ä–æ–∑—Ä–∞—á–Ω–æ –∏ —Ç–∏–ø–æ–±–µ–∑–æ–ø–∞—Å–Ω–æ –ø–µ—Ä–µ–¥–∞–≤–∞—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –º–µ–∂–¥—É —Å–ª–æ—è–º–∏.

---

# üì¶ `internal/app/config.go`

```go
package app

// ScanConfig ‚Äî –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è
type ScanConfig struct {
	RootDir   string
	Exclude   []string
	Output    string
	Pretty    bool
	Workers   int
	SkipMD5   bool
	IOLimit   int
	Resume    bool // TODO: –ø–æ–∫–∞ –Ω–µ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–æ –≤ stream-—Ä–µ–∂–∏–º–µ
}

// MergeConfig ‚Äî –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è
type MergeConfig struct {
	Files          []string
	Output         string
	Pretty         bool
	Dedupe         bool
	MergeFlat      bool
	MergeChildren  bool
}
```

---

# üì¶ `cmd/fsjson/main.go`

```go
package main

import (
	"flag"
	"log"
	"runtime"
	"strings"

	"fsjson/internal/app"
	"fsjson/internal/infrastructure"
)

var (
	dirFlag           = flag.String("dir", ".", "–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è")
	excludeFlag       = flag.String("exclude", "", "–ò—Å–∫–ª—é—á–µ–Ω–∏—è —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é")
	outputFlag        = flag.String("output", "structure.json", "–í—ã—Ö–æ–¥–Ω–æ–π JSON-—Ñ–∞–π–ª")
	prettyFlag        = flag.Bool("pretty", false, "–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞—Ç—å JSON –∫—Ä–∞—Å–∏–≤–æ")
	streamFlag        = flag.Bool("stream", false, "–ü–æ—Ç–æ–∫–æ–≤–∞—è –∑–∞–ø–∏—Å—å –≤ temp")
	resumeFlag        = flag.Bool("resume", false, "–ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ (—Ç–æ–ª—å–∫–æ —Å --stream)")
	mergeFlag         = flag.String("merge", "", "–°–ø–∏—Å–æ–∫ JSON-—Ñ–∞–π–ª–æ–≤ —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é –¥–ª—è –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è")
	workersFlag       = flag.Int("workers", runtime.NumCPU(), "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –ø–æ—Ç–æ–∫–æ–≤ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è")
	skipMd5Flag       = flag.Bool("no-md5", false, "–ù–µ –≤—ã—á–∏—Å–ª—è—Ç—å MD5 –¥–ª—è —Ñ–∞–π–ª–æ–≤")
	ioLimitFlag       = flag.Int("io-limit", 16, "–ú–∞–∫—Å–∏–º—É–º –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö I/O –æ–ø–µ—Ä–∞—Ü–∏–π (—á—Ç–µ–Ω–∏–µ/MD5/Stat)")
	dedupeFlag        = flag.Bool("dedupe", false, "–£–¥–∞–ª—è—Ç—å –¥—É–±–ª–∏–∫–∞—Ç—ã –ø–æ FullPathOrig –ø—Ä–∏ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–∏ JSON —Ñ–∞–π–ª–æ–≤")
	mergeFlatFlag     = flag.Bool("merge-flat", false, "–°–æ—Ö—Ä–∞–Ω—è—Ç—å –æ–±—ä–µ–¥–∏–Ω—ë–Ω–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ –ø–ª–æ—Å–∫–æ–º –≤–∏–¥–µ ([]FileInfo)")
	mergeChildrenFlag = flag.Bool("merge-children", false, "–û–±—ä–µ–¥–∏–Ω—è—Ç—å —Ç–æ–ª—å–∫–æ –¥–æ—á–µ—Ä–Ω–∏–µ —ç–ª–µ–º–µ–Ω—Ç—ã –∫–æ—Ä–Ω–µ–π")
	webFlag           = flag.Bool("web", false, "–ó–∞–ø—É—Å—Ç–∏—Ç—å –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ JSON")
	fileFlag          = flag.String("file", "", "JSON-—Ñ–∞–π–ª –¥–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ –≤ –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–µ")
)

func main() {
	flag.Parse()

	// WEB —Ä–µ–∂–∏–º
	if *webFlag {
		if *fileFlag == "" {
			log.Fatal("–£–∫–∞–∂–∏—Ç–µ JSON-—Ñ–∞–π–ª —á–µ—Ä–µ–∑ --file")
		}
		infrastructure.StartWebServer(*fileFlag)
		return
	}

	// MERGE —Ä–µ–∂–∏–º
	if *mergeFlag != "" {
		cfg := app.MergeConfig{
			Files:         splitCSV(*mergeFlag),
			Output:        *outputFlag,
			Pretty:        *prettyFlag,
			Dedupe:        *dedupeFlag,
			MergeFlat:     *mergeFlatFlag,
			MergeChildren: *mergeChildrenFlag,
		}
		app.MergeMode(cfg)
		return
	}

	// SCAN —Ä–µ–∂–∏–º
	scanCfg := app.ScanConfig{
		RootDir: *dirFlag,
		Exclude: splitCSV(*excludeFlag),
		Output:  *outputFlag,
		Pretty:  *prettyFlag,
		Workers: *workersFlag,
		SkipMD5: *skipMd5Flag,
		IOLimit: *ioLimitFlag,
		Resume:  *resumeFlag,
	}

	if *streamFlag {
		app.ProcessParallelStream(scanCfg)
	} else {
		app.ProcessParallel(scanCfg)
	}
}

func splitCSV(s string) []string {
	if s == "" {
		return nil
	}
	parts := strings.Split(s, ",")
	out := make([]string, 0, len(parts))
	for _, p := range parts {
		p = strings.TrimSpace(strings.ToLower(p))
		if p != "" {
			out = append(out, p)
		}
	}
	return out
}
```

---

# üì¶ `internal/app/merge_mode.go`  (–æ–±–Ω–æ–≤–ª—ë–Ω –ø–æ–¥ —Ñ–ª–∞–≥–∏)

```go
package app

import (
	"encoding/json"
	"fmt"
	"os"
	"strings"

	"fsjson/internal/domain/model"
	"fsjson/internal/domain/service"
	"fsjson/internal/infrastructure"
)

func MergeMode(cfg MergeConfig) {
	fmt.Printf("üîó –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ %d —Ñ–∞–π–ª–æ–≤...\n", len(cfg.Files))

	all := make([]model.FileInfo, 0, 10000)
	roots := make([]model.FileInfo, 0, len(cfg.Files))

	var seen map[string]struct{}
	if cfg.Dedupe {
		seen = make(map[string]struct{})
		fmt.Println("‚öôÔ∏è  –í–∫–ª—é—á–µ–Ω–æ —É–¥–∞–ª–µ–Ω–∏–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –ø–æ FullPathOrig")
	} else {
		fmt.Println("‚öôÔ∏è  –î—É–±–ª–∏–∫–∞—Ç—ã –Ω–µ –±—É–¥—É—Ç —É–¥–∞–ª—è—Ç—å—Å—è")
	}

	for _, file := range cfg.Files {
		file = strings.TrimSpace(file)
		if file == "" {
			continue
		}
		fmt.Printf("üì• –ß—Ç–µ–Ω–∏–µ %s...\n", file)
		data, err := os.ReadFile(file)
		if err != nil {
			fmt.Printf("‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è %s: %v\n", file, err)
			continue
		}

		var parsedFlat []model.FileInfo
		var parsedTree model.FileInfo

		// []FileInfo
		if err := json.Unmarshal(data, &parsedFlat); err == nil && len(parsedFlat) > 0 {
			fmt.Printf("üìÑ %s: flat (%d)\n", file, len(parsedFlat))
			all = service.AppendFlatUnique(all, parsedFlat, seen)
			roots = append(roots, service.AssembleNestedFromFlat(parsedFlat))
			continue
		}
		// FileInfo
		if err := json.Unmarshal(data, &parsedTree); err == nil && (parsedTree.FullName != "" || len(parsedTree.Children) > 0) {
			fmt.Printf("üå≤ %s: –¥–µ—Ä–µ–≤–æ (%d –¥–µ—Ç–µ–π)\n", file, len(parsedTree.Children))
			all = service.AppendFlatUnique(all, service.FlattenTree(parsedTree), seen)
			roots = append(roots, parsedTree)
			continue
		}
		fmt.Printf("‚ö†Ô∏è %s: –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç\n", file)
	}

	if len(all) == 0 && len(roots) == 0 {
		fmt.Println("‚ö†Ô∏è –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è ‚Äî –ø—Ä–æ–≤–µ—Ä—å—Ç–µ –≤—Ö–æ–¥–Ω—ã–µ JSON-—Ñ–∞–π–ª—ã.")
		return
	}

	// –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: --merge-children
	if cfg.MergeChildren {
		fmt.Println("üß© –†–µ–∂–∏–º: –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –¥–æ—á–µ—Ä–Ω–∏—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –∫–æ—Ä–Ω–µ–π (--merge-children)")
		root := service.MergeRootChildren(roots, cfg.Dedupe)
		service.ComputeDirSizes(&root)
		service.RecountChildCounts(&root)
		infrastructure.WriteFinalJSONAtomic(cfg.Output, root, cfg.Pretty)
		infrastructure.DiagnoseJSONShape(cfg.Output)
		fmt.Printf("‚úÖ –ò—Ç–æ–≥–æ–≤—ã–π –∫–æ—Ä–µ–Ω—å: %s | %s\n", root.FullName, cfg.Output)
		return
	}

	// –û–±—ã—á–Ω–∞—è —Å–±–æ—Ä–∫–∞
	if cfg.MergeFlat {
		fmt.Println("üì§ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ —Ñ–æ—Ä–º–∞—Ç–µ flat ([]FileInfo)")
		infrastructure.WriteFlatJSONAtomic(cfg.Output, all, cfg.Pretty)
		infrastructure.DiagnoseJSONShape(cfg.Output)
		fmt.Printf("‚úÖ –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ. –ò—Ç–æ–≥–æ–≤—ã–π —Ñ–∞–π–ª: %s\n", cfg.Output)
		return
	}

	fmt.Println("üì§ –°–±–æ—Ä–∫–∞ –∏–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–æ–≥–æ –¥–µ—Ä–µ–≤–∞...")
	root := service.AssembleNestedFromFlat(all)
	service.ComputeDirSizes(&root)
	service.RecountChildCounts(&root)
	infrastructure.WriteFinalJSONAtomic(cfg.Output, root, cfg.Pretty)
	infrastructure.DiagnoseJSONShape(cfg.Output)
	fmt.Printf("‚úÖ –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ. –ò—Ç–æ–≥–æ–≤—ã–π —Ñ–∞–π–ª: %s\n", cfg.Output)
}
```

---

# üì¶ `internal/app/stream_mode.go`  (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç –≤—Å–µ —Ñ–ª–∞–≥–∏)

```go
package app

import (
	"bufio"
	"encoding/json"
	"fmt"
	"log"
	"os"
	"path/filepath"
	"runtime"
	"sync"
	"sync/atomic"
	"time"

	"fsjson/internal/domain/model"
	"fsjson/internal/domain/service"
	"fsjson/internal/infrastructure"
)

// ProcessParallelStream ‚Äî –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–µ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Å –ø–æ—Ç–æ–∫–æ–≤–æ–π –∑–∞–ø–∏—Å—å—é
func ProcessParallelStream(cfg ScanConfig) {
	start := time.Now()
	rootAbs, _ := filepath.Abs(cfg.RootDir)
	fmt.Printf("üìÅ –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–µ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ (stream): %s\n", rootAbs)
	fmt.Printf("‚öôÔ∏è  Workers: %d | I/O limit: %d | MD5: %v | pretty: %v\n",
		cfg.Workers, cfg.IOLimit, !cfg.SkipMD5, cfg.Pretty)
	if cfg.Resume {
		fmt.Println("‚ÑπÔ∏è  --resume: TODO (–ø–æ–∫–∞ –Ω–µ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–æ –¥–ª—è stream-—Ä–µ–∂–∏–º–∞)")
	}

	tempFile := deriveTempName(cfg.Output)
	f, err := os.OpenFile(tempFile, os.O_CREATE|os.O_RDWR|os.O_TRUNC, 0644)
	if err != nil {
		log.Fatal(err)
	}
	defer f.Close()

	writer := bufio.NewWriter(f)
	_, _ = writer.WriteString("[\n")

	jobs := make(chan string, cfg.Workers*4)
	results := make(chan model.FileInfo, cfg.Workers*4)

	infrastructure.InitIOLimiter(cfg.IOLimit)

	var wg sync.WaitGroup
	var processed int64

	// –í–æ—Ä–∫–µ—Ä—ã
	for i := 0; i < cfg.Workers; i++ {
		wg.Add(1)
		go func() {
			defer wg.Done()
			for path := range jobs {
				// –∏—Å–∫–ª—é—á–µ–Ω–∏—è
				if service.ShouldExclude(path, cfg.Exclude) {
					continue
				}
				fi, err := os.Stat(path)
				if err != nil {
					continue
				}
				// –∏–Ω—ä–µ–∫—Ü–∏—è I/O-–æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π –≤ ReadDir –∏ FileMD5
				entry := service.ProcessPathWith(path, fi, cfg.SkipMD5,
					func(dir string) int {
						return infrastructure.WithIOLimitValue(func() int {
							list, _ := os.ReadDir(dir)
							return len(list)
						})
					},
					func(p string) string {
						return infrastructure.WithIOLimitValue(func() string {
							return service.FileMD5(p)
						})
					},
				)
				if entry.FullName != "" {
					results <- entry
				}
			}
		}()
	}

	// Writer
	var writerWG sync.WaitGroup
	writerWG.Add(1)
	go func() {
		defer writerWG.Done()
		first := true
		encFirst := func() { first = false }
		for r := range results {
			b, _ := json.Marshal(r)
			if !first {
				_, _ = writer.WriteString(",\n")
			} else {
				encFirst()
			}
			_, _ = writer.Write(b)

			if atomic.AddInt64(&processed, 1)%500 == 0 {
				_ = writer.Flush()
				printProgress(processed)
			}
		}
	}()

	// Producer
	go func() {
		defer close(jobs)
		filepath.WalkDir(cfg.RootDir, func(path string, d os.DirEntry, err error) error {
			if err == nil {
				jobs <- path
			}
			return nil
		})
	}()

	wg.Wait()
	close(results)
	writerWG.Wait()
	_, _ = writer.WriteString("\n]\n")
	_ = writer.Flush()

	fmt.Printf("‚úÖ –ü–æ—Ç–æ–∫–æ–≤—ã–π JSON —Å–æ–∑–¥–∞–Ω: %s\n", tempFile)

	flat, err := readFlatArrayFromFile(tempFile)
	if err != nil {
		log.Fatalf("–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è temp: %v", err)
	}
	root := service.AssembleNestedFromFlat(flat)
	service.ComputeDirSizes(&root)
	infrastructure.WriteFinalJSONAtomic(cfg.Output, root, cfg.Pretty)
	infrastructure.DiagnoseJSONShape(cfg.Output)

	fmt.Printf("üéâ –ó–∞–≤–µ—Ä—à–µ–Ω–æ. –§–∞–π–ª–æ–≤: %d | %v\n", processed, time.Since(start))
}

func deriveTempName(output string) string {
	if output == "" {
		return "scan_temp.json"
	}
	ext := filepath.Ext(output)
	base := output[:len(output)-len(ext)]
	return base + "_temp.json"
}

func readFlatArrayFromFile(path string) ([]model.FileInfo, error) {
	data, err := os.ReadFile(path)
	if err != nil {
		return nil, err
	}
	var arr []model.FileInfo
	if err := json.Unmarshal(data, &arr); err != nil {
		return nil, err
	}
	return arr, nil
}

func printProgress(n int64) {
	if n%1000 == 0 {
		var m runtime.MemStats
		runtime.ReadMemStats(&m)
		fmt.Printf("üìä %8d —Ñ–∞–π–ª–æ–≤ | %.1f MB RAM\n", n, float64(m.Alloc)/1024.0/1024.0)
	}
}
```

---

# üì¶ `internal/app/parallel_mode.go`  (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç –≤—Å–µ —Ñ–ª–∞–≥–∏)

```go
package app

import (
	"fmt"
	"os"
	"path/filepath"
	"runtime"
	"sync"
	"sync/atomic"
	"time"

	"fsjson/internal/domain/model"
	"fsjson/internal/domain/service"
	"fsjson/internal/infrastructure"
)

// ProcessParallel ‚Äî –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–µ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –±–µ–∑ –ø–æ—Ç–æ–∫–æ–≤–æ–π –∑–∞–ø–∏—Å–∏
func ProcessParallel(cfg ScanConfig) {
	start := time.Now()
	rootAbs, _ := filepath.Abs(cfg.RootDir)
	fmt.Printf("üìÅ –ù–∞—á–∞–ª–æ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è: %s\n", rootAbs)
	fmt.Printf("‚öôÔ∏è  Workers: %d | I/O limit: %d | MD5: %v | pretty: %v\n",
		cfg.Workers, cfg.IOLimit, !cfg.SkipMD5, cfg.Pretty)

	infrastructure.InitIOLimiter(cfg.IOLimit)

	jobs := make(chan string, cfg.Workers*4)
	results := make(chan model.FileInfo, cfg.Workers*4)
	var wg sync.WaitGroup
	var processed int64

	for i := 0; i < cfg.Workers; i++ {
		wg.Add(1)
		go func() {
			defer wg.Done()
			for path := range jobs {
				if service.ShouldExclude(path, cfg.Exclude) {
					continue
				}
				fi, err := os.Stat(path)
				if err != nil {
					continue
				}
				entry := service.ProcessPathWith(path, fi, cfg.SkipMD5,
					func(dir string) int {
						return infrastructure.WithIOLimitValue(func() int {
							list, _ := os.ReadDir(dir)
							return len(list)
						})
					},
					func(p string) string {
						return infrastructure.WithIOLimitValue(func() string {
							return service.FileMD5(p)
						})
					},
				)
				if entry.FullName != "" {
					results <- entry
				}
			}
		}()
	}

	go func() {
		defer close(jobs)
		filepath.WalkDir(cfg.RootDir, func(path string, d os.DirEntry, err error) error {
			if err == nil {
				jobs <- path
			}
			return nil
		})
	}()

	go func() {
		wg.Wait()
		close(results)
	}()

	var flat []model.FileInfo
	for r := range results {
		if r.FullName != "" {
			flat = append(flat, r)
			if atomic.AddInt64(&processed, 1)%1000 == 0 {
				printProgress(processed)
			}
		}
	}

	root := service.AssembleNestedFromFlat(flat)
	service.ComputeDirSizes(&root)
	infrastructure.WriteFinalJSONAtomic(cfg.Output, root, cfg.Pretty)
	infrastructure.DiagnoseJSONShape(cfg.Output)

	fmt.Printf("‚úÖ –ì–æ—Ç–æ–≤–æ. –§–∞–π–ª–æ–≤: %d | %v\n", processed, time.Since(start))
}

func printProgress(n int64) {
	if n%1000 == 0 {
		var m runtime.MemStats
		runtime.ReadMemStats(&m)
		fmt.Printf("üìä %8d —Ñ–∞–π–ª–æ–≤ | %.1f MB RAM\n", n, float64(m.Alloc)/1024.0/1024.0)
	}
}
```

---

# üì¶ `internal/domain/service/scanner.go`  (**–¥–æ–±–∞–≤–∏–ª ProcessPathWith –∏ ShouldExclude**)

```go
package service

import (
	"crypto/md5"
	"encoding/hex"
	"io"
	"os"
	"path/filepath"
	"strings"

	"fsjson/internal/domain/model"
)

// ProcessPathWith ‚Äî –∫–∞–∫ ProcessPath, –Ω–æ —Å –∏–Ω—ä–µ–∫—Ü–∏–µ–π I/O-—Ñ—É–Ω–∫—Ü–∏–π (–¥–ª—è –ª–∏–º–∏—Ç–∞)
func ProcessPathWith(
	path string,
	info os.FileInfo,
	skipMd5 bool,
	readDirCount func(dir string) int,
	fileMD5 func(path string) string,
) model.FileInfo {
	parent := filepath.Dir(path)
	if parent == "." {
		parent = ""
	}

	size := int64(0)
	if !info.IsDir() {
		size = info.Size()
	}

	entry := model.FileInfo{
		IsDir:        info.IsDir(),
		FullName:     info.Name(),
		Ext:          strings.TrimPrefix(strings.ToLower(filepath.Ext(info.Name())), "."),
		NameOnly:     strings.TrimSuffix(info.Name(), filepath.Ext(info.Name())),
		SizeBytes:    size,
		SizeHuman:    HumanSize(size),
		FullPath:     path,
		FullPathOrig: path,
		ParentDir:    parent,
		Created:      info.ModTime(),
		Updated:      info.ModTime(),
		Perm:         info.Mode().String(),
		FileType:     DetectFileType(info.Name()),
	}

	if info.IsDir() {
		if readDirCount != nil {
			entry.ChildCount = readDirCount(path)
		}
		if !skipMd5 {
			entry.Md5 = Md5String(info.Name())
		}
	} else if !skipMd5 && fileMD5 != nil {
		entry.Md5 = fileMD5(path)
	}

	return entry
}

// ProcessPath ‚Äî –≤–µ—Ä—Å–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é (–±–µ–∑ –≤–Ω–µ—à–Ω–µ–≥–æ I/O –ª–∏–º–∏—Ç–∞)
func ProcessPath(path string, info os.FileInfo, skipMd5 bool) model.FileInfo {
	return ProcessPathWith(path, info, skipMd5,
		func(dir string) int {
			list, _ := os.ReadDir(dir)
			return len(list)
		},
		func(p string) string {
			return FileMD5(p)
		},
	)
}

// ShouldExclude ‚Äî –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ –ø–æ–¥—Å—Ç—Ä–æ–∫–µ –ü–û–õ–ù–û–ì–û –ø—É—Ç–∏ (—Ä–µ–≥–∏—Å—Ç—Ä–æ–Ω–µ–∑–∞–≤–∏—Å–∏–º–æ)
func ShouldExclude(absPath string, excludes []string) bool {
	pl := strings.ToLower(absPath)
	for _, ex := range excludes {
		if ex != "" && strings.Contains(pl, ex) {
			return true
		}
	}
	return false
}

// --- MD5 helpers (—á–∏—Å—Ç—ã–µ, –±–µ–∑ –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π) ---
func Md5String(s string) string {
	sum := md5.Sum([]byte(s))
	return hex.EncodeToString(sum[:])
}

func FileMD5(path string) string {
	f, err := os.Open(path)
	if err != nil {
		return ""
	}
	defer f.Close()
	h := md5.New()
	if _, err := io.Copy(h, f); err != nil {
		return ""
	}
	return hex.EncodeToString(h.Sum(nil))
}
```

---

‚úÖ –¢–µ–ø–µ—Ä—å **–≤—Å–µ –ø–µ—Ä–µ—á–∏—Å–ª–µ–Ω–Ω—ã–µ —Ñ–ª–∞–≥–∏ —Ä–µ–∞–ª—å–Ω–æ –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è** –≤ –Ω—É–∂–Ω—ã—Ö –º–µ—Å—Ç–∞—Ö, –∏ –ø–æ–≤–µ–¥–µ–Ω–∏–µ –ø—Ä–æ–≥—Ä–∞–º–º—ã —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç CLI-–ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º.

–ï—Å–ª–∏ —Ö–æ—á–µ—à—å, –º–æ–≥—É —Å—Ä–∞–∑—É –ø—Ä–∏–ª–æ–∂–∏—Ç—å –Ω–µ–±–æ–ª—å—à–æ–π `Makefile` –∏ –æ–±–Ω–æ–≤–ª—ë–Ω–Ω—ã–π `README` —Å –ø—Ä–∏–º–µ—Ä–∞–º–∏ –∑–∞–ø—É—Å–∫–æ–≤ —Å —ç—Ç–∏–º–∏ —Ñ–ª–∞–≥–∞–º–∏.
