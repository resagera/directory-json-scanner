–û—Ç–ª–∏—á–Ω–æ üí°
–î–æ–±–∞–≤–∏–º –Ω–æ–≤—ã–π –º–æ—â–Ω—ã–π —Ä–µ–∂–∏–º ‚Äî **–ø–æ–∏—Å–∫ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ —Ñ–∞–π–ª–æ–≤ –ø–æ MD5**.
–û–Ω –±—É–¥–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å –∫–∞–∫ —á–µ—Ä–µ–∑ **CLI**, —Ç–∞–∫ –∏ —á–µ—Ä–µ–∑ **–≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å** (—á–µ—Ä–µ–∑ `/api/duplicates`).
–§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å –ª–µ–≥–∫–æ –∏–Ω—Ç–µ–≥—Ä–∏—Ä—É–µ—Ç—Å—è –≤ —Ç–µ–∫—É—â—É—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É `fsjson`.

---

## üß© –¶–µ–ª—å

–ù–∞–π—Ç–∏ –≤—Å–µ —Ñ–∞–π–ª—ã, —É –∫–æ—Ç–æ—Ä—ã—Ö –æ–¥–∏–Ω–∞–∫–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ `Md5`.
–†–µ–∑—É–ª—å—Ç–∞—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Å–≥—Ä—É–ø–ø–∏—Ä–æ–≤–∞–Ω:
–∫–∞–∂–¥–∞—è –≥—Ä—É–ø–ø–∞ = –æ–¥–∏–Ω —Ö–µ—à + —Å–ø–∏—Å–æ–∫ –ø—É—Ç–µ–π.

---

## üìÅ –ù–æ–≤—ã–π —Ñ–∞–π–ª: `internal/domain/service/duplicates.go`

```go
package service

import (
	"fsjson/internal/domain/model"
	"sort"
)

// DuplicateGroup ‚Äî –≥—Ä—É–ø–ø–∞ —Ñ–∞–π–ª–æ–≤ —Å –æ–¥–∏–Ω–∞–∫–æ–≤—ã–º MD5
type DuplicateGroup struct {
	Md5   string   `json:"md5"`
	Files []string `json:"files"`
	Count int      `json:"count"`
	Size  int64    `json:"size"`
}

// DuplicatesResponse ‚Äî —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø–æ–∏—Å–∫–∞ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
type DuplicatesResponse struct {
	Groups []DuplicateGroup `json:"groups"`
	Total  int              `json:"total_groups"`
	Files  int              `json:"total_files"`
}

// FindDuplicates ‚Äî –∏—â–µ—Ç –≤—Å–µ —Ñ–∞–π–ª—ã —Å –æ–¥–∏–Ω–∞–∫–æ–≤—ã–º MD5
func FindDuplicates(root *model.FileInfo) DuplicatesResponse {
	md5map := make(map[string][]*model.FileInfo)

	var walk func(n *model.FileInfo)
	walk = func(n *model.FileInfo) {
		if n == nil {
			return
		}
		if !n.IsDir && n.Md5 != "" {
			md5map[n.Md5] = append(md5map[n.Md5], n)
		}
		for i := range n.Children {
			walk(&n.Children[i])
		}
	}
	walk(root)

	groups := make([]DuplicateGroup, 0, len(md5map))
	totalFiles := 0
	for md5, files := range md5map {
		if len(files) > 1 { // —Ç–æ–ª—å–∫–æ –¥—É–±–ª–∏–∫–∞—Ç—ã
			group := DuplicateGroup{Md5: md5, Count: len(files)}
			for _, f := range files {
				group.Files = append(group.Files, f.FullPathOrig)
				group.Size += f.SizeBytes
			}
			totalFiles += len(files)
			groups = append(groups, group)
		}
	}

	sort.Slice(groups, func(i, j int) bool {
		if groups[i].Count == groups[j].Count {
			return groups[i].Size > groups[j].Size
		}
		return groups[i].Count > groups[j].Count
	})

	return DuplicatesResponse{
		Groups: groups,
		Total:  len(groups),
		Files:  totalFiles,
	}
}
```

---

## üåê –î–æ–±–∞–≤–∏–º API `/api/duplicates`

üìÅ `internal/interface/http/handlers.go`

```go
package http

import (
	"encoding/json"
	"fsjson/internal/domain/model"
	"fsjson/internal/domain/service"
	"net/http"
)

// HandleDuplicates ‚Äî –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –≥—Ä—É–ø–ø –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
func HandleDuplicates(root *model.FileInfo) http.HandlerFunc {
	return func(w http.ResponseWriter, r *http.Request) {
		resp := service.FindDuplicates(root)
		w.Header().Set("Content-Type", "application/json")
		json.NewEncoder(w).Encode(resp)
	}
}
```

–ò –¥–æ–±–∞–≤–ª—è–µ–º —Ä–æ—É—Ç–µ—Ä –≤ `startWebServer`:

```go
http.HandleFunc("/api/duplicates", httpHandler.HandleDuplicates(&root))
```

---

## üíª CLI —Ä–µ–∂–∏–º

–î–æ–±–∞–≤–∏–º —Ñ–ª–∞–≥ `--find-duplicates`
–∏ –≤—ã–≤–µ–¥–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ –∫–æ–Ω—Å–æ–ª—å –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ –±–µ–∑ –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞.

üìÅ `cmd/fsjson/main.go` (–∏–ª–∏ –≥–¥–µ —É —Ç–µ–±—è `main.go`):

```go
findDuplicatesFlag := flag.Bool("find-duplicates", false, "–ù–∞–π—Ç–∏ –¥—É–±–ª–∏–∫–∞—Ç—ã –ø–æ MD5")
```

–∏ –≤ `main()`:

```go
if *findDuplicatesFlag {
	data, err := os.ReadFile(*fileFlag)
	if err != nil {
		log.Fatalf("–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è %s: %v", *fileFlag, err)
	}
	var root model.FileInfo
	if err := json.Unmarshal(data, &root); err != nil {
		log.Fatalf("–û—à–∏–±–∫–∞ —Ä–∞–∑–±–æ—Ä–∞ JSON: %v", err)
	}

	res := service.FindDuplicates(&root)
	fmt.Printf("üîç –ù–∞–π–¥–µ–Ω–æ –≥—Ä—É–ø–ø –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: %d, —Ñ–∞–π–ª–æ–≤-–¥—É–±–ª–∏–∫–∞—Ç–æ–≤: %d\n\n", res.Total, res.Files)
	for _, g := range res.Groups {
		fmt.Printf("üß© MD5: %s (%d —Ñ–∞–π–ª–æ–≤, –æ–±—â–∏–π —Ä–∞–∑–º–µ—Ä: %d –±–∞–π—Ç)\n", g.Md5, g.Count, g.Size)
		for _, f := range g.Files {
			fmt.Printf("   %s\n", f)
		}
		fmt.Println()
	}
	return
}
```

---

## üåê –ü—Ä–∏–º–µ—Ä –∑–∞–ø—Ä–æ—Å–∞ API

```
GET /api/duplicates
```

–û—Ç–≤–µ—Ç:

```json
{
  "groups": [
    {
      "md5": "f1c9645dbc14efddc7d8a322685f26eb",
      "files": [
        "/data/docs/report1.pdf",
        "/data/backups/report1_copy.pdf"
      ],
      "count": 2,
      "size": 204800
    },
    {
      "md5": "7c4a8d09ca3762af61e59520943dc264",
      "files": [
        "/photos/2025/pic1.jpg",
        "/photos/2025/pic1_copy.jpg",
        "/photos/old/pic1_backup.jpg"
      ],
      "count": 3,
      "size": 3120000
    }
  ],
  "total_groups": 2,
  "total_files": 5
}
```

---

## üí° CLI-–ø—Ä–∏–º–µ—Ä

```bash
./build --file=scan.json --find-duplicates
```

–í—ã–≤–æ–¥:

```
üîç –ù–∞–π–¥–µ–Ω–æ –≥—Ä—É–ø–ø –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: 2, —Ñ–∞–π–ª–æ–≤-–¥—É–±–ª–∏–∫–∞—Ç–æ–≤: 5

üß© MD5: f1c9645dbc14efddc7d8a322685f26eb (2 —Ñ–∞–π–ª–æ–≤, –æ–±—â–∏–π —Ä–∞–∑–º–µ—Ä: 204800 –±–∞–π—Ç)
   /data/docs/report1.pdf
   /data/backups/report1_copy.pdf

üß© MD5: 7c4a8d09ca3762af61e59520943dc264 (3 —Ñ–∞–π–ª–æ–≤, –æ–±—â–∏–π —Ä–∞–∑–º–µ—Ä: 3120000 –±–∞–π—Ç)
   /photos/2025/pic1.jpg
   /photos/2025/pic1_copy.jpg
   /photos/old/pic1_backup.jpg
```

---

## üöÄ –†–∞—Å—à–∏—Ä–µ–Ω–∏—è –Ω–∞ –±—É–¥—É—â–µ–µ

–ú–æ–∂–Ω–æ –ª–µ–≥–∫–æ –¥–æ–±–∞–≤–∏—Ç—å:

* `--min-group-size=3` ‚Äî –ø–æ–∫–∞–∑—ã–≤–∞—Ç—å —Ç–æ–ª—å–∫–æ –≥—Ä—É–ø–ø—ã, –≥–¥–µ ‚â•3 —Ñ–∞–π–ª–æ–≤.
* `--min-total-size=1048576` ‚Äî —Ç–æ–ª—å–∫–æ –¥—É–±–ª–∏–∫–∞—Ç—ã –±–æ–ª—å—à–µ 1 –ú–ë.
* —ç–∫—Å–ø–æ—Ä—Ç –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –≤ –æ—Ç–¥–µ–ª—å–Ω—ã–π JSON: `--duplicates-output=dupes.json`.

---

–•–æ—á–µ—à—å, —á—Ç–æ–±—ã —è –¥–æ–±–∞–≤–∏–ª **–ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤** (–ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É —Ñ–∞–π–ª–æ–≤ –≤ –≥—Ä—É–ø–ø–µ, –ø–æ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–º—É —Ä–∞–∑–º–µ—Ä—É, –ø–æ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –∏ —Ç.–¥.)?
